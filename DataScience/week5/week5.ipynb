{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science with Python: Week 5\n",
    "\n",
    "Alexander L. Hayes\n",
    "\n",
    "## numpy\n",
    "\n",
    "* Scientific computing library that provides a powerful array object.\n",
    "* Building block for virtually all scientific computing and machine learning libraries in Python.\n",
    "* Provides versatile utilities to interface with C++/Fortran code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "int64\n",
      "3\n",
      "(3,)\n",
      "[3 6 9]\n",
      "[ 4  8 12]\n",
      "[  2.71828183   7.3890561   20.08553692]\n",
      "8\n",
      "24\n",
      "[0 0 0 0]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create Arrays\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 5, 7])\n",
    "\n",
    "# Python Type\n",
    "print(type(a))\n",
    "\n",
    "# System Type\n",
    "print(a.dtype)\n",
    "\n",
    "# Size:   size(a) or a.size\n",
    "print(a.size)\n",
    "\n",
    "# Shape:  shape(a) or a.shape\n",
    "print(a.shape)\n",
    "\n",
    "# Multiply contents of an array by a constant:\n",
    "# Multiply all elements in array a by 3.\n",
    "print(3 * a)\n",
    "\n",
    "# Adding arrays together:\n",
    "print(a + (3 * a))\n",
    "\n",
    "# Apply functions to arrays:\n",
    "print(np.exp(a))\n",
    "\n",
    "# We can see the bytes per item:\n",
    "print(a.itemsize)\n",
    "\n",
    "# Bytes for a whole array:\n",
    "print(a.nbytes)\n",
    "\n",
    "# Set all items in a numpy array to 0:\n",
    "b.fill(0)\n",
    "print(b)\n",
    "\n",
    "# You can do this with slicing as well:\n",
    "b[:] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"Where\" function\n",
    "# Flattening arrays\n",
    "# Reshape arrays by copying (so long as the dimensions match)\n",
    "# Reduce\n",
    "# Outer\n",
    "# Broadcasting: Operating on arrays where dimensions do not match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas\n",
    "\n",
    "* http://pandas.pydata.com\n",
    "* \"high-performance, easy-to-use data structures and data analysis tools.\"\n",
    "* similar to abilities to SQL\n",
    "* Joins and merges, groupby, automatic plotting, multi-level indices, time series operations.\n",
    "\n",
    "Data structures include \"series\" (1-dimensional) and \"data frames\" (2-dimensional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    5.0\n",
       "4    7.0\n",
       "5    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series([1, 2, 3, 5, 7, np.NaN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   a         b         c         d         e         f\n",
      "2017-10-01  0.227356 -0.659369  0.234637 -1.566748  1.032988 -1.296588\n",
      "2017-10-02  0.308783  0.243784 -2.174104 -1.224522  0.223567 -1.039132\n",
      "...\n",
      "                   a         b         c         d         e         f\n",
      "2017-10-09 -2.024588 -0.797938  0.132482  0.546872  1.014856 -0.551235\n",
      "2017-10-10  0.510113  0.349511  0.173303  0.773859  0.576421 -0.675496\n",
      "\n",
      "Perhaps we are only interested in the columsns:\n",
      " Index(['a', 'b', 'c', 'd', 'e', 'f'], dtype='object')\n",
      "\n",
      "Perhaps we just want the values in the data itself:\n",
      " [[ 0.2273564  -0.65936876  0.23463735 -1.56674813  1.03298801 -1.296588  ]\n",
      " [ 0.3087829   0.24378363 -2.17410362 -1.22452162  0.22356659 -1.03913239]\n",
      " [ 0.721305    0.95331838 -3.04662615 -0.97575049 -0.22056173 -1.63978097]\n",
      " [-0.37261465  0.02682163 -0.59060704 -0.08584807  0.63660515 -1.14946581]\n",
      " [-0.08339633 -0.22751029 -0.45419094  0.32416022  2.21993116  0.4364759 ]\n",
      " [ 0.45830321  0.70944541  1.10844594  0.07595521 -0.16746316  1.05463523]\n",
      " [ 0.32990958 -0.7635632  -0.61761145  0.45635327 -1.55759851 -0.3722621 ]\n",
      " [-0.72448848 -1.08472109  1.99459866  0.3513641  -0.4373876   1.56865771]\n",
      " [-2.02458829 -0.7979381   0.13248218  0.54687199  1.0148559  -0.55123461]\n",
      " [ 0.51011315  0.34951138  0.17330269  0.7738589   0.57642088 -0.67549636]]\n"
     ]
    }
   ],
   "source": [
    "dates = pd.date_range('20171001', periods=10)\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(10, 6), index=dates, columns=pd.Series(['a', 'b', 'c', 'd', 'e', 'f']))\n",
    "\n",
    "print(df.head(2)) # First two rows\n",
    "print('...')\n",
    "print(df.tail(2)) # Last two rows\n",
    "\n",
    "print('\\nPerhaps we are only interested in the columsns:\\n', df.columns)\n",
    "print('\\nPerhaps we just want the values in the data itself:\\n', df.values)\n",
    "\n",
    "# Sort by index or values:\n",
    "# missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn\n",
    "\n",
    "* Optimized and easy-to-use implementations of common machine learning algorithms.\n",
    "* Built on scipy, numpy, and pandas.\n",
    "* A good model requires good features; features should strongly correlate with outcomes, be relatively independent of each other, and fit on the same scale. Typically this requires domain expertise.\n",
    "* Three basic types of algorithms: classification, regression, and clustering.\n",
    "\n",
    "For demonstration, we will use the classic Iris dataset (it is included in scikitlearn), which includes 150 samples each with four features (sepal length, sepal width, petal length, and petal width), classified by species (three)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "\n",
    "tree.DecisionTreeClassifier(maxDepth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
